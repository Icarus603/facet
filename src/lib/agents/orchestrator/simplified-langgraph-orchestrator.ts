/**
 * Simplified LangGraph Multi-Agent System
 * 
 * Uses working LangGraph patterns compatible with current package versions
 * Implements proper multi-agent coordination with proxy support
 */

import { StateGraph, END } from '@langchain/langgraph';
import { BaseMessage, HumanMessage, AIMessage, SystemMessage } from '@langchain/core/messages';
import { ChatOpenAI } from '@langchain/openai';
import { v4 as uuidv4 } from 'uuid';
import { HttpsProxyAgent } from 'https-proxy-agent';
import {
  ChatRequest,
  ChatResponse,
  AgentExecutionResult,
  AGENT_NAMES
} from '@/lib/types/api-contract';
import { WebSocketBroadcaster } from '@/app/api/ws/route';

// Simple state interface that works with current LangGraph
interface SimpleFACETState {
  messages: BaseMessage[];
  userId: string;
  messageId: string;
  conversationId: string;
  urgencyLevel: 'normal' | 'elevated' | 'crisis';
  userPreferences?: any;
  agentResults: AgentExecutionResult[];
  emotionalState?: any;
  riskAssessment?: any;
  startTime: number;
  finalResponse?: string;
  responseConfidence?: number;
  currentStep: string;
  isComplete: boolean;
}

export class SimplifiedLangGraphOrchestrator {
  private graph: any;
  private llm: ChatOpenAI;

  constructor() {
    this.initializeOpenAI();
    this.buildGraph();
  }

  private initializeOpenAI() {
    const httpProxy = process.env.HTTP_PROXY || process.env.http_proxy;
    const httpsProxy = process.env.HTTPS_PROXY || process.env.https_proxy;
    
    let clientOptions: any = {
      openAIApiKey: process.env.OPENAI_API_KEY,
      modelName: process.env.DEFAULT_MODEL || 'gpt-5-2025-08-07',
      temperature: 1.0, // GPT-5 only supports temperature=1.0
      timeout: 120000, // 2 minutes
      maxRetries: 5,
    };

    if (httpProxy || httpsProxy) {
      const proxyUrl = httpsProxy || httpProxy;
      const proxyAgent = new HttpsProxyAgent(proxyUrl, {
        timeout: 60000,
        keepAlive: true,
        keepAliveMsecs: 10000
      });
      
      clientOptions.configuration = {
        httpAgent: proxyAgent,
        httpsAgent: proxyAgent,
      };
      
      console.log('üåê Simplified LangGraph: Proxy configured for:', proxyUrl);
    }

    this.llm = new ChatOpenAI(clientOptions);
  }

  private buildGraph() {
    // Create StateGraph with simple state channels
    const workflow = new StateGraph<SimpleFACETState>({
      channels: {
        messages: {
          value: (x: BaseMessage[], y: BaseMessage[]) => x.concat(y),
          default: () => [],
        },
        userId: {
          value: (x: string, y?: string) => y ?? x,
          default: () => "",
        },
        messageId: {
          value: (x: string, y?: string) => y ?? x,
          default: () => "",
        },
        conversationId: {
          value: (x: string, y?: string) => y ?? x,
          default: () => "",
        },
        urgencyLevel: {
          value: (x: 'normal' | 'elevated' | 'crisis', y?: 'normal' | 'elevated' | 'crisis') => y ?? x,
          default: () => 'normal' as const,
        },
        userPreferences: {
          value: (x: any, y?: any) => y ?? x,
          default: () => ({}),
        },
        agentResults: {
          value: (x: AgentExecutionResult[], y: AgentExecutionResult[]) => x.concat(y),
          default: () => [],
        },
        emotionalState: {
          value: (x: any, y?: any) => y ?? x,
          default: () => ({}),
        },
        riskAssessment: {
          value: (x: any, y?: any) => y ?? x,
          default: () => ({}),
        },
        startTime: {
          value: (x: number, y?: number) => y ?? x,
          default: () => Date.now(),
        },
        finalResponse: {
          value: (x: string, y?: string) => y ?? x,
          default: () => "",
        },
        responseConfidence: {
          value: (x: number, y?: number) => y ?? x,
          default: () => 0.8,
        },
        currentStep: {
          value: (x: string, y?: string) => y ?? x,
          default: () => "start",
        },
        isComplete: {
          value: (x: boolean, y?: boolean) => y ?? x,
          default: () => false,
        },
      }
    });

    // Add nodes for each agent
    workflow.addNode("supervisor", this.supervisorAgent.bind(this));
    workflow.addNode("emotion_analyzer", this.emotionAnalyzerAgent.bind(this));
    workflow.addNode("crisis_monitor", this.crisisMonitorAgent.bind(this));
    workflow.addNode("therapy_advisor", this.therapyAdvisorAgent.bind(this));

    // Define control flow
    workflow.setEntryPoint("supervisor");
    
    workflow.addConditionalEdges(
      "supervisor",
      this.supervisorRouting.bind(this),
      {
        "emotion_analyzer": "emotion_analyzer",
        "crisis_monitor": "crisis_monitor", 
        "therapy_advisor": "therapy_advisor",
        "FINISH": END,
      }
    );

    workflow.addConditionalEdges(
      "emotion_analyzer",
      this.agentRouting.bind(this),
      {
        "supervisor": "supervisor",
        "FINISH": END,
      }
    );

    workflow.addConditionalEdges(
      "crisis_monitor",
      this.agentRouting.bind(this),
      {
        "supervisor": "supervisor",
        "FINISH": END,
      }
    );

    workflow.addConditionalEdges(
      "therapy_advisor",
      this.agentRouting.bind(this),
      {
        "FINISH": END,
      }
    );

    // Compile the workflow
    this.graph = workflow.compile();

    console.log('‚úÖ Simplified LangGraph workflow compiled successfully');
  }

  /**
   * Main processing entry point
   */
  async processMessage(request: ChatRequest, userId: string): Promise<ChatResponse> {
    const startTime = Date.now();
    const messageId = request.messageId || uuidv4();
    const conversationId = request.conversationId || uuidv4();

    try {
      console.log('üöÄ LangGraph processing message:', request.message.substring(0, 50));

      // 1. Notify WebSocket that orchestration is starting
      WebSocketBroadcaster.notifyOrchestrationStart(userId, conversationId, {
        strategy: 'Simplified LangGraph Multi-Agent Analysis',
        estimatedTimeMs: 10000,
        agentsInvolved: ['therapy_advisor'], // Will be dynamic based on routing
        executionPattern: 'sequential'
      });

      // Initialize state
      const initialState: SimpleFACETState = {
        messages: [new HumanMessage({ content: request.message })],
        userId,
        messageId,
        conversationId,
        urgencyLevel: this.detectUrgency(request.message),
        userPreferences: request.userPreferences,
        agentResults: [],
        startTime,
        currentStep: "start",
        isComplete: false,
      };

      // Invoke the graph - let it complete naturally
      const result = await this.graph.invoke(initialState, {
        recursionLimit: 20, // Prevent infinite loops
      });

      // Extract final response from messages
      const finalMessage = result.messages[result.messages.length - 1];
      
      // Use the longer response between finalResponse and message content
      const finalResponseCandidate = result.finalResponse || "";
      const messageContentCandidate = finalMessage?.content || "";
      const finalResponse = finalResponseCandidate.length > messageContentCandidate.length 
        ? finalResponseCandidate 
        : messageContentCandidate || "I'm here to support you. How are you feeling?";

      console.log('üîç Response extraction debug:', {
        hasFinalResponse: !!result.finalResponse,
        finalResponseLength: result.finalResponse?.length || 0,
        finalMessageType: finalMessage?._getType(),
        finalMessageContentLength: finalMessage?.content?.length || 0,
        extractedResponseLength: finalResponse.length,
        resultKeys: Object.keys(result)
      });

      console.log('‚úÖ LangGraph processing complete:', {
        finalResponse: finalResponse.substring(0, 50),
        fullResponseLength: finalResponse.length,
        actualResponseStart: finalResponse.substring(0, 100),
        agentResults: result.agentResults.length,
        processingTime: Date.now() - startTime
      });

      // 2. Notify WebSocket that orchestration is complete
      WebSocketBroadcaster.notifyOrchestrationComplete(userId, conversationId, {
        totalTimeMs: Date.now() - startTime,
        finalConfidence: result.responseConfidence || 0.8,
        agentsCompleted: result.agentResults.length,
        agentsFailed: 0,
        response: finalResponse
      });

      const responseObject = {
        content: finalResponse,
        messageId,
        conversationId,
        orchestration: {
          strategy: "Simplified LangGraph Multi-Agent Analysis",
          reasoning: "Coordinated emotion analysis and therapy response",
          totalAgentsInvolved: result.agentResults.length,
          executionPattern: 'serial' as const,
          executionPlan: [],
          agentResults: result.agentResults,
          timing: {
            planningTimeMs: 100,
            coordinationOverheadMs: 50,
            parallelExecutionTimeMs: 0,
            synthesisTimeMs: 200,
            totalTimeMs: Date.now() - startTime
          },
          confidence: {
            overall: result.responseConfidence || 0.8,
            reasoning: "Multi-agent analysis completed successfully"
          }
        },
        metadata: {
          timestamp: new Date().toISOString(),
          processingTimeMs: Date.now() - startTime,
          agentVersion: "simplified-langgraph-v1.0",
          responseConfidence: result.responseConfidence || 0.8,
          emotionalState: result.emotionalState,
          riskAssessment: result.riskAssessment,
          recommendedFollowUp: [],
          warningFlags: [],
        }
      };

      console.log('üîç Final response object debug:', {
        contentLength: responseObject.content.length,
        contentPreview: responseObject.content.substring(0, 100)
      });

      return responseObject;

    } catch (error) {
      console.error('LangGraph execution error:', error);
      
      return {
        content: "I'm here to support you. How are you feeling right now?",
        messageId,
        conversationId,
        orchestration: {
          strategy: "Fallback Response",
          reasoning: "System error occurred, using fallback response",
          totalAgentsInvolved: 0,
          executionPattern: 'serial' as const,
          executionPlan: [],
          agentResults: [],
          timing: {
            planningTimeMs: 0,
            coordinationOverheadMs: 0,
            parallelExecutionTimeMs: 0,
            synthesisTimeMs: 0,
            totalTimeMs: Date.now() - startTime
          },
          confidence: {
            overall: 0.5,
            reasoning: "Fallback response due to system error"
          }
        },
        metadata: {
          timestamp: new Date().toISOString(),
          processingTimeMs: Date.now() - startTime,
          agentVersion: "simplified-langgraph-v1.0",
          responseConfidence: 0.5,
          recommendedFollowUp: [],
          warningFlags: ['execution_error'],
        }
      };
    }
  }

  /**
   * Supervisor agent - controls routing
   */
  private async supervisorAgent(state: SimpleFACETState): Promise<Partial<SimpleFACETState>> {
    const userMessage = state.messages.find(m => m._getType() === 'human')?.content || '';
    console.log('üéØ Supervisor analyzing:', userMessage.substring(0, 50));
    
    // Simple routing logic
    let nextStep = 'therapy_advisor'; // Default to therapy
    
    if (this.detectCrisis(userMessage)) {
      nextStep = 'crisis_monitor';
    } else if (this.detectEmotionalContent(userMessage)) {
      nextStep = 'emotion_analyzer';
    }
    
    console.log('üìç Supervisor routing to:', nextStep);
    
    return {
      messages: [new AIMessage({ content: `Routing to ${nextStep}`, name: 'supervisor' })],
      currentStep: nextStep,
    };
  }

  /**
   * Emotion Analyzer Agent
   */
  private async emotionAnalyzerAgent(state: SimpleFACETState): Promise<Partial<SimpleFACETState>> {
    const startTime = Date.now();
    const userMessage = state.messages.find(m => m._getType() === 'human')?.content || '';

    console.log('üé≠ Emotion analyzer processing:', userMessage.substring(0, 50));

    // Notify WebSocket that emotion analyzer is starting
    WebSocketBroadcaster.notifyAgentStatusUpdate(state.userId, state.conversationId, {
      agentName: 'emotion_analyzer',
      status: 'running',
      progress: 0
    });

    try {
      const systemPrompt = new SystemMessage({
        content: `Analyze emotional state using VAD model. Return JSON: {"valence": 0.0, "arousal": 0.0, "dominance": 0.0, "primaryEmotion": "neutral", "intensity": 0.5, "confidence": 0.8}`
      });

      const messages = [systemPrompt, new HumanMessage({ content: userMessage })];
      const response = await this.llm.invoke(messages);
      
      let emotionResult;
      try {
        emotionResult = JSON.parse(response.content.toString());
      } catch {
        emotionResult = {
          valence: 0.0, arousal: 0.0, dominance: 0.0,
          primaryEmotion: 'neutral', intensity: 0.5, confidence: 0.8
        };
      }

      const agentResult: AgentExecutionResult = {
        agentName: AGENT_NAMES.EMOTION_ANALYZER,
        agentDisplayName: 'Emotion Analyzer',
        agentIcon: 'üé≠',
        assignedTask: 'Analyze emotional state',
        inputData: { message: userMessage },
        executionTimeMs: Date.now() - startTime,
        executionType: 'sequential',
        startTimeMs: Date.now() - state.startTime,
        endTimeMs: Date.now() - state.startTime,
        result: emotionResult,
        confidence: emotionResult.confidence,
        success: true,
        reasoning: 'Emotional analysis complete',
        keyInsights: [emotionResult.primaryEmotion],
        recommendationsToOrchestrator: ['Continue to therapy advisor'],
        influenceOnFinalResponse: 0.8,
        contributedInsights: [emotionResult.primaryEmotion]
      };

      console.log('‚úÖ Emotion analysis complete:', emotionResult.primaryEmotion);

      // Notify WebSocket that emotion analyzer is completed
      WebSocketBroadcaster.notifyAgentStatusUpdate(state.userId, state.conversationId, {
        agentName: 'emotion_analyzer',
        status: 'completed',
        progress: 100,
        executionTimeMs: Date.now() - startTime,
        confidence: emotionResult.confidence
      });

      return {
        messages: [new AIMessage({ content: `Emotion: ${emotionResult.primaryEmotion}`, name: 'emotion_analyzer' })],
        agentResults: [agentResult],
        emotionalState: emotionResult,
        currentStep: 'emotion_complete',
      };

    } catch (error) {
      console.error('‚ùå Emotion analyzer error:', error);
      return {
        messages: [new AIMessage({ content: 'Emotion analysis failed', name: 'emotion_analyzer' })],
        currentStep: 'emotion_error',
      };
    }
  }

  /**
   * Crisis Monitor Agent
   */
  private async crisisMonitorAgent(state: SimpleFACETState): Promise<Partial<SimpleFACETState>> {
    const startTime = Date.now();
    const userMessage = state.messages.find(m => m._getType() === 'human')?.content || '';

    console.log('üÜò Crisis monitor processing:', userMessage.substring(0, 50));

    // Notify WebSocket that crisis monitor is starting
    WebSocketBroadcaster.notifyAgentStatusUpdate(state.userId, state.conversationId, {
      agentName: 'crisis_monitor',
      status: 'running',
      progress: 0
    });

    try {
      const systemPrompt = new SystemMessage({
        content: `Assess crisis risk. Return JSON: {"riskLevel": "low", "riskFactors": [], "confidence": 0.8}`
      });

      const messages = [systemPrompt, new HumanMessage({ content: userMessage })];
      const response = await this.llm.invoke(messages);
      
      let crisisResult;
      try {
        crisisResult = JSON.parse(response.content.toString());
      } catch {
        crisisResult = {
          riskLevel: 'low', riskFactors: [], confidence: 0.8
        };
      }

      const agentResult: AgentExecutionResult = {
        agentName: AGENT_NAMES.CRISIS_MONITOR,
        agentDisplayName: 'Crisis Monitor',
        agentIcon: 'üÜò',
        assignedTask: 'Assess crisis risk',
        inputData: { message: userMessage },
        executionTimeMs: Date.now() - startTime,
        executionType: 'sequential',
        startTimeMs: Date.now() - state.startTime,
        endTimeMs: Date.now() - state.startTime,
        result: crisisResult,
        confidence: crisisResult.confidence,
        success: true,
        reasoning: 'Crisis assessment complete',
        keyInsights: [crisisResult.riskLevel],
        recommendationsToOrchestrator: ['Continue to therapy advisor'],
        influenceOnFinalResponse: 0.9,
        contributedInsights: crisisResult.riskFactors
      };

      console.log('‚úÖ Crisis assessment complete:', crisisResult.riskLevel);

      // Notify WebSocket that crisis monitor is completed
      WebSocketBroadcaster.notifyAgentStatusUpdate(state.userId, state.conversationId, {
        agentName: 'crisis_monitor',
        status: 'completed',
        progress: 100,
        executionTimeMs: Date.now() - startTime,
        confidence: crisisResult.confidence
      });

      return {
        messages: [new AIMessage({ content: `Risk: ${crisisResult.riskLevel}`, name: 'crisis_monitor' })],
        agentResults: [agentResult],
        riskAssessment: crisisResult,
        currentStep: 'crisis_complete',
      };

    } catch (error) {
      console.error('‚ùå Crisis monitor error:', error);
      return {
        messages: [new AIMessage({ content: 'Crisis assessment failed', name: 'crisis_monitor' })],
        currentStep: 'crisis_error',
      };
    }
  }

  /**
   * Therapy Advisor Agent
   */
  private async therapyAdvisorAgent(state: SimpleFACETState): Promise<Partial<SimpleFACETState>> {
    const startTime = Date.now();
    const userMessage = state.messages.find(m => m._getType() === 'human')?.content || '';
    
    console.log('üí¨ Therapy advisor processing:', userMessage.substring(0, 50));

    // Notify WebSocket that therapy advisor is starting
    WebSocketBroadcaster.notifyAgentStatusUpdate(state.userId, state.conversationId, {
      agentName: 'therapy_advisor',
      status: 'running',
      progress: 0
    });

    try {
      const systemPrompt = new SystemMessage({
        content: `You are a compassionate mental health therapist. Provide a warm, supportive response to the user.
        
Emotional context: ${JSON.stringify(state.emotionalState || {})}
Risk assessment: ${JSON.stringify(state.riskAssessment || {})}

Provide an empathetic, professional therapeutic response.`
      });

      const messages = [systemPrompt, new HumanMessage({ content: userMessage })];
      const response = await this.llm.invoke(messages);

      const finalResponse = response.content.toString();
      console.log('üîç Raw OpenAI response debug:', {
        responseType: typeof response.content,
        contentLength: finalResponse.length,
        fullContent: finalResponse,
        truncated: finalResponse.length < 100 // Assume complete responses are longer
      });
      console.log('‚úÖ Therapy response generated:', finalResponse.substring(0, 50));

      // Create agent result for tracking
      const agentResult: AgentExecutionResult = {
        agentName: AGENT_NAMES.THERAPY_ADVISOR,
        agentDisplayName: 'Therapy Advisor',
        agentIcon: 'üí¨',
        assignedTask: 'Provide therapeutic response',
        inputData: { 
          message: userMessage,
          emotionalState: state.emotionalState,
          riskAssessment: state.riskAssessment
        },
        executionTimeMs: Date.now() - startTime,
        executionType: 'sequential',
        startTimeMs: Date.now() - state.startTime,
        endTimeMs: Date.now() - state.startTime,
        result: { response: finalResponse },
        confidence: 0.85,
        success: true,
        reasoning: 'Therapeutic response generated successfully',
        keyInsights: ['therapeutic_support'],
        recommendationsToOrchestrator: ['Continue monitoring user wellbeing'],
        influenceOnFinalResponse: 1.0,
        contributedInsights: ['therapeutic_response']
      };

      // Notify WebSocket that therapy advisor is completed
      WebSocketBroadcaster.notifyAgentStatusUpdate(state.userId, state.conversationId, {
        agentName: 'therapy_advisor',
        status: 'completed',
        progress: 100,
        executionTimeMs: Date.now() - startTime,
        confidence: 0.85
      });

      return {
        messages: [response],
        agentResults: [agentResult],
        finalResponse,
        responseConfidence: 0.85,
        currentStep: 'complete',
        isComplete: true,
      };

    } catch (error) {
      console.error('‚ùå Therapy advisor error:', error);
      
      // Create failed agent result
      const failedResult: AgentExecutionResult = {
        agentName: AGENT_NAMES.THERAPY_ADVISOR,
        agentDisplayName: 'Therapy Advisor',
        agentIcon: 'üí¨',
        assignedTask: 'Provide therapeutic response',
        inputData: { message: userMessage },
        executionTimeMs: Date.now() - startTime,
        executionType: 'sequential',
        startTimeMs: Date.now() - state.startTime,
        endTimeMs: Date.now() - state.startTime,
        result: { error: error instanceof Error ? error.message : 'Unknown error' },
        confidence: 0.5,
        success: false,
        reasoning: 'Therapy advisor execution failed',
        keyInsights: ['execution_error'],
        recommendationsToOrchestrator: ['Use fallback response'],
        influenceOnFinalResponse: 0.5,
        contributedInsights: ['error_fallback']
      };

      return {
        messages: [new AIMessage({ content: "I'm here to support you. How are you feeling right now?" })],
        agentResults: [failedResult],
        finalResponse: "I'm here to support you. How are you feeling right now?",
        currentStep: 'complete',
        isComplete: true,
      };
    }
  }

  /**
   * Routing functions
   */
  private supervisorRouting(state: SimpleFACETState): string {
    if (state.currentStep === 'start') {
      return state.currentStep; // Will use supervisor logic
    }
    return state.currentStep === 'complete' ? 'FINISH' : state.currentStep;
  }

  private agentRouting(state: SimpleFACETState): string {
    if (state.isComplete) {
      return 'FINISH';
    }
    
    // Check if we need therapy advisor
    if (state.emotionalState || state.riskAssessment) {
      return 'supervisor'; // Go back to supervisor to route to therapy
    }
    
    return 'supervisor';
  }

  private detectUrgency(message: string): 'normal' | 'elevated' | 'crisis' {
    const crisisKeywords = ['suicide', 'kill myself', 'end it all', 'hurt myself'];
    const lowerMessage = message.toLowerCase();
    
    if (crisisKeywords.some(keyword => lowerMessage.includes(keyword))) {
      return 'crisis';
    }
    
    const elevatedKeywords = ['overwhelming', 'desperate', 'breaking down'];
    if (elevatedKeywords.some(keyword => lowerMessage.includes(keyword))) {
      return 'elevated';  
    }
    
    return 'normal';
  }

  private detectCrisis(message: string): boolean {
    return this.detectUrgency(message) === 'crisis';
  }

  private detectEmotionalContent(message: string): boolean {
    const emotionalKeywords = ['anxious', 'sad', 'angry', 'worried', 'stressed', 'happy', 'excited'];
    return emotionalKeywords.some(keyword => message.toLowerCase().includes(keyword));
  }
}

// Create singleton instance
export const simplifiedLangGraphOrchestrator = new SimplifiedLangGraphOrchestrator();